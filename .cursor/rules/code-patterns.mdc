---
description: Code style, patterns, and best practices for Python development
globs:
  - "src/**/*.py"
  - "tests/**/*.py"
alwaysApply: false
---

# Code Patterns and Best Practices

## Python Style

### Ruff Configuration
```toml
line-length = 120
indent-width = 4
target-version = "py313"
lint.select = ["I", "F401"]  # Import sorting and unused imports
```

### Type Hints
- **Always use type hints** for function parameters and return values
- Use `from typing import Optional, Type, TypeVar` for complex types
- Use `Path` from `pathlib` for file paths (never strings)
- Use `BaseModel` from `pydantic` for all configuration and data models

```python
from pathlib import Path
from typing import Optional, Type, TypeVar
from pydantic import BaseModel, Field

T = TypeVar("T", bound=BaseModel)

def load_config(args, handler_config: Type[T], file_key: str = "") -> T:
    # Implementation
    pass
```

## Pydantic Patterns

### Configuration Models
```python
class HandlerConfig(BaseModel):
    repo_path: Path = Field(..., description="The path to the repository")
    exclude_something: bool = Field(default=False, description="Exclude something")
    
    @model_validator(mode="after")
    def validate_paths(self) -> "HandlerConfig":
        if not self.repo_path.exists():
            raise ValueError(f"repo_path {self.repo_path} does not exist")
        return self
```

### Field Descriptions
- **Always provide descriptions** for CLI argument generation
- Use clear, concise language
- Include defaults in description when helpful

## Async/Await Patterns

### Handler Methods
```python
class MyHandler(BaseHandler):
    async def handle(self):
        # All handler methods are async
        result = await self.agent.run()
        return result
```

### Concurrent Execution
```python
# Run multiple agents concurrently with error isolation
tasks = [agent1.run(), agent2.run(), agent3.run()]
results = await asyncio.gather(*tasks, return_exceptions=True)

# Check results
for i, result in enumerate(results):
    if isinstance(result, Exception):
        Logger.error(f"Agent #{i} failed: {result}", exc_info=True)
    else:
        Logger.info(f"Agent #{i} completed successfully")
```

## Configuration Loading

### Multi-Source Configuration Pattern

```python
# Load configuration with precedence: defaults → file → CLI
config = load_config(args, HandlerConfig, file_key="section.subsection")

# File-based config (YAML)
file_config = load_config_from_file(args, "analyzer")

# CLI arguments
cli_config = load_config_as_dict(args, HandlerConfig)

# Merge with precedence
final_config = merge_dicts(file_config, cli_config)
```

### Environment Variables

```python
# Required variables (raise KeyError if missing)
MY_API_KEY = os.environ["MY_API_KEY"]

# Optional with defaults
MY_TIMEOUT = int(os.getenv("MY_TIMEOUT", "180"))

# Boolean conversion
MY_FLAG = str_to_bool(os.getenv("MY_FLAG", "true"))
```

## Logging Patterns

### Logger Usage
```python
from utils import Logger

# Initialize once per execution
Logger.init(logs_dir, file_level=logging.INFO, console_level=logging.WARNING)

# Use throughout code
Logger.info("Starting process")
Logger.debug("Debug details", {"key": "value"})
Logger.warning("Warning message")
Logger.error("Error occurred", exc_info=True)
```

### Structured Logging
```python
# Pass dictionaries for structured data
Logger.info("Agent completed", {
    "agent_name": agent.name,
    "total_tokens": result.usage().total_tokens,
    "execution_time": elapsed_time,
})
```

## OpenTelemetry Tracing

### Span Creation
```python
from opentelemetry import trace

tracer = trace.get_tracer("my-component")

with tracer.start_as_current_span("Operation Name") as span:
    span.set_attributes({
        "repo_path": str(repo_path),
        "config_key": config_value,
    })
    span.add_event(name="Starting operation", attributes={"detail": "value"})
    
    # Do work
    result = await do_work()
    
    span.set_attribute("result_size", len(result))
```

## Error Handling

### Graceful Degradation
```python
# Partial success is acceptable
if len(missing_files) == len(analysis_files):
    Logger.error("Complete failure: no files generated")
    raise ValueError("Complete failure")

if missing_files:
    Logger.warning(f"Partial success: {successful_count}/{len(analysis_files)} files")
    # Continue execution
```

### Cleanup Guarantees
```python
try:
    # Operations
    await process_project(project)
finally:
    # Always cleanup
    cleanup_project(project)
```

## File Operations

### Path Handling
```python
from pathlib import Path

# Always use Path objects
repo_path = Path("/path/to/repo")
config_path = repo_path / ".ai" / "config.yaml"

# Check existence
if config_path.exists():
    content = config_path.read_text()

# Create directories
output_dir = repo_path / ".ai" / "docs"
output_dir.mkdir(parents=True, exist_ok=True)

# Write files
output_file = output_dir / "analysis.md"
output_file.write_text(content)
```

## CLI Argument Generation

### Dynamic Argument Creation

```python
def _add_field_arg(parser: argparse.ArgumentParser, field_name: str, field_info: FieldInfo):
    arg_name = f"--{field_name.replace('_', '-')}"
    help_text = field_info.description
    
    # Boolean flags use store_true with None default
    if field_info.annotation in [bool, Optional[bool]]:
        parser.add_argument(
            arg_name,
            action="store_true",
            default=None,  # None means "not specified"
            help=help_text,
            required=field_info.is_required(),
        )
    else:
        parser.add_argument(
            arg_name,
            default=None,
            help=help_text,
            required=field_info.is_required(),
        )
```

## Testing Considerations

- Mock LLM responses using pydantic-ai's testing utilities
- Use temporary directories for file operations
- Mock GitLab API calls with python-gitlab's test utilities
- Test configuration loading with various precedence scenarios
- Test partial success scenarios in concurrent execution